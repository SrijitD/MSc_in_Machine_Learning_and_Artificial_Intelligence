{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7/python\"\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/java/jdk1.8.0_161/jre\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/home/ec2-user/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.7-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/25 19:23:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Trial\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Download data from [here](https://www.kaggle.com/mczielinski/bitcoin-historical-data)\n",
    "data = spark.read.csv('bitcoin.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Timestamp: integer (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume_(BTC): double (nullable = true)\n",
      " |-- Volume_(Currency): double (nullable = true)\n",
      " |-- Weighted_Price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|\n",
      "|1325317980| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318040| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318100| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318160| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318220| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318280| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318340| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318400| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318460| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318520| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318580| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318640| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318700| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318760| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318820| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318880| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325318940| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319000| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "|1325319060| NaN| NaN| NaN|  NaN|         NaN|              NaN|           NaN|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation from the data table\n",
    "\n",
    "There are a lot of NaN values. Check if the compete table is the same way, filled of NaN values or there is some meaningful data. \n",
    "\n",
    "### Question \n",
    "Confirm the table has more than 1 meaningful occurances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======================================>                   (2 + 1) / 3]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|1327629480| 3.8| 3.8| 3.8|  3.8|        0.27|            1.026|           3.8|\n",
      "|1328036700| 3.8| 3.8| 3.8|  3.8|         5.0|             19.0|           3.8|\n",
      "|1329582120|4.14|4.14|4.14| 4.14|  2.24383721|     9.2894860494|          4.14|\n",
      "|1329582180|4.14|4.14|4.14| 4.14|  4.58743279|     18.991971751|          4.14|\n",
      "|1329415380|4.15|4.15|4.15| 4.15|  1.07011258|      4.440967207|          4.15|\n",
      "|1329358140|4.17|4.17|4.17| 4.17|         4.0|            16.68|          4.17|\n",
      "|1329601860|4.23|4.23|4.23| 4.23|         5.0|            21.15|          4.23|\n",
      "|1329567300|4.24|4.24|4.21| 4.21| 11.48636364|     48.454590924|  4.2184447962|\n",
      "|1329587760|4.25|4.25|4.25| 4.25|        20.0|             85.0|          4.25|\n",
      "|1329567000|4.27|4.27|4.27| 4.27|         2.0|             8.54|          4.27|\n",
      "|1329357060| 4.3| 4.3| 4.3|  4.3|        2.21|            9.503|           4.3|\n",
      "|1329610860| 4.3| 4.3| 4.3|  4.3|        33.6|           144.48|           4.3|\n",
      "|1329610920| 4.3| 4.3| 4.3|  4.3|        15.0|             64.5|           4.3|\n",
      "|1329566940| 4.3| 4.3|4.28| 4.28|         0.8|             3.43|        4.2875|\n",
      "|1329610980| 4.3| 4.3| 4.3|  4.3|    8.466772|       36.4071196|           4.3|\n",
      "|1329812400| 4.3| 4.3| 4.3|  4.3| 39.40696733|     169.44995952|           4.3|\n",
      "|1329646020|4.33|4.33|4.33| 4.33|        3.55|          15.3715|          4.33|\n",
      "|1329356820|4.35|4.35|4.35| 4.35|        0.97|           4.2195|          4.35|\n",
      "|1329356940|4.35|4.35| 4.3|  4.3|        2.76|          11.8695|  4.3005434783|\n",
      "|1329812280|4.35|4.35|4.35| 4.35|        50.0|            217.5|          4.35|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# lets arrange the data in accending order of some column say High. if there are values in it they will be first. \n",
    "data.orderBy(data.High).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are values in the data set it is not completly empty. \n",
    "\n",
    "### Question \n",
    "\n",
    "Remove all the rows with NaN values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdrop = data.na.drop()\n",
    "\n",
    "# drop all rows with empty values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "| Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|1325317920|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|\n",
      "|1325346600|4.39|4.39|4.39| 4.39|        48.0|           210.72|          4.39|\n",
      "|1325350740| 4.5|4.57| 4.5| 4.57| 37.86229723|     171.38033753|  4.5264114983|\n",
      "|1325350800|4.58|4.58|4.58| 4.58|         9.0|            41.22|          4.58|\n",
      "|1325391360|4.58|4.58|4.58| 4.58|       1.502|          6.87916|          4.58|\n",
      "|1325431680|4.84|4.84|4.84| 4.84|        10.0|             48.4|          4.84|\n",
      "|1325457900| 5.0| 5.0| 5.0|  5.0|        10.1|             50.5|           5.0|\n",
      "|1325534640| 5.0| 5.0| 5.0|  5.0|      19.048|            95.24|           5.0|\n",
      "|1325591100|5.32|5.32|5.32| 5.32|  2.41917293|     12.869999988|          5.32|\n",
      "|1325600520|5.14|5.14|5.14| 5.14|        0.68|           3.4952|          5.14|\n",
      "|1325602440|5.26|5.26|5.26| 5.26| 29.31939163|     154.21999997|          5.26|\n",
      "|1325604720|5.29|5.29|5.29| 5.29| 29.30245747|     155.01000002|          5.29|\n",
      "|1325610600|5.29|5.29|5.29| 5.29| 11.28544423|     59.699999977|          5.29|\n",
      "|1325610840|5.14|5.14|5.14| 5.14|        0.02|           0.1028|          5.14|\n",
      "|1325611560|5.29|5.29|5.29| 5.29|        11.0|            58.19|          5.29|\n",
      "|1325611620|5.29|5.29|5.29| 5.29|  4.01081466|     21.217209551|          5.29|\n",
      "|1325650620|4.93|4.93|4.93| 4.93|        2.32|          11.4376|          4.93|\n",
      "|1325653500|4.93|4.93|4.93| 4.93|        9.68|          47.7224|          4.93|\n",
      "|1325680860|5.19|5.19|5.19| 5.19|   2.6416185|     13.710000015|          5.19|\n",
      "|1325681820|5.19|5.19|5.19| 5.19|  8.72447013|     45.279999975|          5.19|\n",
      "+----------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfdrop.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "Find the percentage empty rows.\n",
    "\n",
    "percentage of non empty rows = (number of non-empty rows/number total number of rows)*100\n",
    "\n",
    "percentage of empty rows = 100 - percentage of non empty rows\n",
    "\n",
    "answer = 30.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.602459928475795"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100- (  (dfdrop.count()/data.count())*100  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the large amout of time it takes to compute this. It is because .count() is an action it is being performed right now. Moreover, the data set is quite large so it is taking time.\n",
    "\n",
    "Let's check how large the data set actually is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3613769"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfdrop.count()\n",
    "#number of rows in dataframe with no empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4857377"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()\n",
    "#number of rows in the complete data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handeling the timestamp column\n",
    "\n",
    "Now lets try to convert the timestamp in more readable format.\n",
    "\n",
    "### Question \n",
    "Convert the Timestamp column in normal datetime\n",
    "\n",
    "hint : you can find the required function here https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.functions.from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfdrop.withColumn('Timestamp',from_unixtime('Timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|          Timestamp|Open|High| Low|Close|Volume_(BTC)|Volume_(Currency)|Weighted_Price|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+\n",
      "|2011-12-31 07:52:00|4.39|4.39|4.39| 4.39|  0.45558087|     2.0000000193|          4.39|\n",
      "|2011-12-31 15:50:00|4.39|4.39|4.39| 4.39|        48.0|           210.72|          4.39|\n",
      "|2011-12-31 16:59:00| 4.5|4.57| 4.5| 4.57| 37.86229723|     171.38033753|  4.5264114983|\n",
      "|2011-12-31 17:00:00|4.58|4.58|4.58| 4.58|         9.0|            41.22|          4.58|\n",
      "|2012-01-01 04:16:00|4.58|4.58|4.58| 4.58|       1.502|          6.87916|          4.58|\n",
      "|2012-01-01 15:28:00|4.84|4.84|4.84| 4.84|        10.0|             48.4|          4.84|\n",
      "|2012-01-01 22:45:00| 5.0| 5.0| 5.0|  5.0|        10.1|             50.5|           5.0|\n",
      "|2012-01-02 20:04:00| 5.0| 5.0| 5.0|  5.0|      19.048|            95.24|           5.0|\n",
      "|2012-01-03 11:45:00|5.32|5.32|5.32| 5.32|  2.41917293|     12.869999988|          5.32|\n",
      "|2012-01-03 14:22:00|5.14|5.14|5.14| 5.14|        0.68|           3.4952|          5.14|\n",
      "|2012-01-03 14:54:00|5.26|5.26|5.26| 5.26| 29.31939163|     154.21999997|          5.26|\n",
      "|2012-01-03 15:32:00|5.29|5.29|5.29| 5.29| 29.30245747|     155.01000002|          5.29|\n",
      "|2012-01-03 17:10:00|5.29|5.29|5.29| 5.29| 11.28544423|     59.699999977|          5.29|\n",
      "|2012-01-03 17:14:00|5.14|5.14|5.14| 5.14|        0.02|           0.1028|          5.14|\n",
      "|2012-01-03 17:26:00|5.29|5.29|5.29| 5.29|        11.0|            58.19|          5.29|\n",
      "|2012-01-03 17:27:00|5.29|5.29|5.29| 5.29|  4.01081466|     21.217209551|          5.29|\n",
      "|2012-01-04 04:17:00|4.93|4.93|4.93| 4.93|        2.32|          11.4376|          4.93|\n",
      "|2012-01-04 05:05:00|4.93|4.93|4.93| 4.93|        9.68|          47.7224|          4.93|\n",
      "|2012-01-04 12:41:00|5.19|5.19|5.19| 5.19|   2.6416185|     13.710000015|          5.19|\n",
      "|2012-01-04 12:57:00|5.19|5.19|5.19| 5.19|  8.72447013|     45.279999975|          5.19|\n",
      "+-------------------+----+----+----+-----+------------+-----------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "Find the 90th percentile of weighted price\n",
    "\n",
    "answer = '8541.8561284'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'11489.95077'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Weighted_Price').summary('90%').head(1)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUESTION\n",
    "\n",
    "Find the date time when the weighted price was maximum\n",
    "\n",
    "answer = '2017-12-17 12:24:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol1 = df.select(['Timestamp','Weighted_Price']).orderBy(df['Weighted_Price'].desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice:  \n",
    "How this executes instantly. As there is now action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2021-03-13 20:42:00'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol1.head(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notice:\n",
    "This takes time because it does the previous transformation first. We are using indexing to get to the timestamp in the firstrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Find the total number of occurances when more than 10 Bitcoin was traded\n",
    "\n",
    "ans = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "715191"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Volume_(BTC)']>10).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question \n",
    "\n",
    "Find the average quantity of bitcoin traded per year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import function to find the year form date\n",
    "#import function to round off average\n",
    "\n",
    "from pyspark.sql.functions import year\n",
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new dataframe with a year column\n",
    "\n",
    "dfyear = df.withColumn('Year',year('Timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the averages of the yearly quantity\n",
    "\n",
    "yearavg = dfyear.select(['Year','Volume_(BTC)']).groupBy('Year').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|year| Mean|\n",
      "+----+-----+\n",
      "|2018| 7.77|\n",
      "|2015|14.82|\n",
      "|2013|15.73|\n",
      "|2014|12.62|\n",
      "|2019| 5.89|\n",
      "|2020| 5.92|\n",
      "|2012|21.33|\n",
      "|2016| 5.66|\n",
      "|2011|23.83|\n",
      "|2017| 9.72|\n",
      "|2021| 6.65|\n",
      "+----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#show the yearly averages in a readable format\n",
    "\n",
    "yearavg.select('year',format_number('avg(Volume_(BTC))',2).alias(\"Mean\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
